# 性能对比报告

**测试日期**: 2025-10-13  
**测试环境**: WSL2 + CUDA 12.6 + RTX 4060 Ti (8GB)

---

## 测试配置

### 测试问题
- **问题类型**: 2D Poisson 方程 (-∇²u = f)
- **离散方法**: 5点有限差分模板
- **网格规模**: 64×64, 128×128, 256×256, 512×512
- **收敛标准**: 相对残差 < 1e-6

### 求解器配置

| 库 | 模式 | 求解器 | 预条件器 | 预条件器参数 | 状态 |
|---|------|--------|---------|-------------|------|
| AMGX | GPU | PCG | Jacobi | Block Jacobi | ✅ 成功 |
| HYPRE-CPU | CPU | PCG | BoomerAMG | Falgout粗化 + 对称GS松弛 | ✅ 成功 |
| HYPRE-GPU | GPU | PCG | BoomerAMG | Falgout粗化 + 对称GS松弛 | ✅ 成功 |
| PETSc-CPU | CPU | CG | GAMG | 聚合AMG + 1次平滑 | ✅ 成功 |
| PETSc-GPU | GPU | CG | GAMG | 聚合AMG + 1次平滑 | ✅ 成功 |

### 详细求解器参数

#### AMGX (GPU)
```json
{
  "solver": "PCG",
  "preconditioner": "BLOCK_JACOBI",
  "max_iters": 1000,
  "tolerance": 1e-6,
  "convergence": "RELATIVE_INI_CORE"
}
```

#### HYPRE (CPU/GPU)
```c
求解器: PCG
  - 最大迭代: 1000
  - 收敛容差: 1e-6
  - 双范数: 启用

预条件器: BoomerAMG
  - 粗化类型: 6 (Falgout)
  - 松弛类型: 6 (对称 Gauss-Seidel)
  - 平滑次数: 1
  - 最大层数: 20
```

#### PETSc (CPU/GPU)
```c
求解器: CG (Conjugate Gradient)
  - 最大迭代: 2000
  - 相对容差: 1e-6
  - 绝对容差: 1e-8
  - 残差范数: 未预条件残差

预条件器: GAMG (几何代数多重网格)
  - AMG 类型: 聚合 (Aggregation)
  - 平滑次数: 1
  - 粗化策略: 自适应
```

**注意**: GPU 版本除了执行位置不同，求解器参数完全相同

---

## 性能对比结果

### 规模: 64×64 (4,096 未知数)

| 库 | 求解器 | 预条件器 | Setup (s) | Solve (s) | Total (s) | 迭代数 | 相对残差 |
|---|--------|----------|-----------|-----------|-----------|--------|----------|
| AMGX (GPU) | PCG | Jacobi | 0.0106 | 0.0535 | 0.0641 | 8 | 1.00e-07 |
| HYPRE-CPU | PCG | BoomerAMG | 0.0037 | 0.0016 | 0.0053 | 4 | 3.87e-07 |
| HYPRE-GPU | PCG | BoomerAMG | 0.0038 | 0.0014 | 0.0052 | 4 | 3.87e-07 |
| PETSc-CPU | CG | GAMG | 0.0098 | 0.0016 | 0.0114 | 9 | 2.54e-07 |
| PETSc-GPU | CG | GAMG | 0.2695 | 0.0215 | 0.2910 | 9 | 2.54e-07 |

**🏆 最快**: HYPRE-GPU (0.0052秒)

### 规模: 128×128 (16,384 未知数)

| 库 | 求解器 | 预条件器 | Setup (s) | Solve (s) | Total (s) | 迭代数 | 相对残差 |
|---|--------|----------|-----------|-----------|-----------|--------|----------|
| AMGX (GPU) | PCG | Jacobi | 0.0018 | 0.0643 | 0.0661 | 16 | 1.00e-07 |
| HYPRE-CPU | PCG | BoomerAMG | 0.0165 | 0.0079 | 0.0244 | 4 | 6.70e-07 |
| HYPRE-GPU | PCG | BoomerAMG | 0.0151 | 0.0095 | 0.0246 | 4 | 6.70e-07 |
| PETSc-CPU | CG | GAMG | 0.0309 | 0.0078 | 0.0387 | 10 | 2.28e-07 |
| PETSc-GPU | CG | GAMG | 0.0480 | 0.0154 | 0.0634 | 10 | 2.28e-07 |

**🏆 最快**: HYPRE-CPU (0.0244秒)

### 规模: 256×256 (65,536 未知数)

| 库 | 求解器 | 预条件器 | Setup (s) | Solve (s) | Total (s) | 迭代数 | 相对残差 |
|---|--------|----------|-----------|-----------|-----------|--------|----------|
| AMGX (GPU) | PCG | Jacobi | 0.0025 | 0.1604 | 0.1628 | 31 | 1.00e-07 |
| HYPRE-CPU | PCG | BoomerAMG | 0.0635 | 0.0388 | 0.1023 | 5 | 4.62e-08 |
| HYPRE-GPU | PCG | BoomerAMG | 0.0614 | 0.0318 | 0.0932 | 5 | 4.62e-08 |
| PETSc-CPU | CG | GAMG | 0.1277 | 0.0352 | 0.1629 | 11 | 4.15e-07 |
| PETSc-GPU | CG | GAMG | 0.1260 | 0.0184 | 0.1444 | 11 | 4.15e-07 |

**🏆 最快**: HYPRE-GPU (0.0932秒)

### 规模: 512×512 (262,144 未知数)

| 库 | 求解器 | 预条件器 | Setup (s) | Solve (s) | Total (s) | 迭代数 | 相对残差 |
|---|--------|----------|-----------|-----------|-----------|--------|----------|
| AMGX (GPU) | PCG | Jacobi | 0.0037 | 0.6356 | 0.6393 | 61 | 7.02e-07 |
| HYPRE-CPU | PCG | BoomerAMG | 0.2741 | 0.1589 | 0.4330 | 5 | 9.40e-07 |
| HYPRE-GPU | PCG | BoomerAMG | 0.2635 | 0.1339 | 0.3973 | 5 | 9.40e-07 |
| PETSc-CPU | CG | GAMG | 0.5166 | 0.1874 | 0.7040 | 12 | 7.37e-07 |
| PETSc-GPU | CG | GAMG | 0.4187 | 0.0336 | 0.4523 | 12 | 7.37e-07 |

**🏆 最快**: HYPRE-GPU (0.3973秒)  
**⚡ 求解最快**: PETSc-GPU (0.0336秒 - 比CPU快5.6倍！)

---

## 关键发现

### 1. 收敛效率（迭代次数）

**🥇 HYPRE**: 4-5 次迭代
- BoomerAMG 预条件器对 Poisson 问题效果极佳
- CPU 和 GPU 版本迭代次数完全相同
- 预条件器质量最高

**🥈 AMGX**: 8-61 次迭代  
- Jacobi 预条件器效果较弱
- 随问题规模增长迭代数增加明显
- 应该使用 AMG 预条件器

**🥉 PETSc**: 9-12 次迭代
- GAMG 预条件器效果良好
- 迭代数稳定，不随规模剧增

### 2. 求解时间对比

#### 小规模问题 (64×64)
- GPU 优势不明显
- CPU 求解器更快（Setup 开销小）
- HYPRE 表现最佳

#### 中等规模 (256×256)
- GPU 开始显示优势
- HYPRE-GPU 比 HYPRE-CPU 快约 9%
- AMGX 仍因迭代数多而较慢

#### 大规模问题 (512×512)
- HYPRE-GPU 比 HYPRE-CPU 快约 8%
- GPU 加速效果开始体现
- 需要更大规模才能完全展示 GPU 优势

### 3. CPU vs GPU 对比

**HYPRE-CPU vs HYPRE-GPU** (512×512):
- CPU: 0.433秒
- GPU: 0.397秒
- **GPU 加速比: 1.09× (快 8%)**

原因分析:
- 当前问题规模还不够大
- GPU 需要百万级以上未知数才能充分发挥
- Setup 时间占比较大（GPU 优势主要在 solve）

### 4. 精度对比

所有成功的求解器都达到了 **10⁻⁷ 级别**的相对残差：
- AMGX: 1e-7 到 7e-7
- HYPRE (CPU/GPU): 5e-8 到 9e-7
- PETSc-CPU: 2e-7 到 7e-7

**✅ 精度完全对齐，可以公平对比！**

---

## 总结

### 最佳选择建议

**对于 Poisson 类问题**:
1. **小规模 (<10K 未知数)**: HYPRE-CPU
   - 最快，setup 开销最小
   
2. **中等规模 (10K-100K)**: HYPRE-GPU 或 HYPRE-CPU
   - 两者性能接近
   - GPU 版本稍快
   
3. **大规模 (>100K)**: HYPRE-GPU
   - GPU 优势逐渐体现
   - 建议测试更大规模（百万级）

### 预条件器效果排名

1. **🥇 HYPRE BoomerAMG**: 4-5次迭代，最高效
2. **🥈 PETSc GAMG**: 9-12次迭代，稳定
3. **🥉 AMGX Jacobi**: 8-61次迭代，应改用 AMG

### GPU 加速建议

- **AMGX**: 需要使用更强的预条件器（AMG）
- **HYPRE**: GPU 版本在大规模问题下表现优异
- **PETSc**: GPU 支持在 WSL 环境下不稳定（已知问题）

---

## 未来改进方向

1. ✅ 测试更大规模问题（1024×1024, 2048×2048）
2. ✅ 为 AMGX 配置 AMG 预条件器
3. ⚠️ 解决 PETSc GPU CUDA 内核问题
4. ✅ 添加 3D Poisson 问题测试
5. ✅ 多 GPU 可扩展性测试

---

**结论**: HYPRE BoomerAMG 在 Poisson 问题上表现最佳，GPU 版本在大规模问题下更快。
